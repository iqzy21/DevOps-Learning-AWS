# DevOps-Learning-AWS
I learn AWS

## IAM (Identity and Access Management)

### Users and Groups 

#### Root Account
- Created by default when the AWS account is set up
- Shouldn't be used for everyday tasks
- Keep credentials secure; never share

#### Users
- Represent people or services in your organization
- Can be grouped for easier permission management
- Each has their own login & permissions

#### Groups
- Contain only users (no nested groups)
- Assign permissions to the group ‚Üí applies to all users in it
- A user:
  - Doesn't have to belong to a group
  - Can belong to multiple groups

#### Example (From Diagram)
- **Developers Group**: Michael, Jennifer, Joey
- **Audit Team Group**: Zid
- **Operations Group**: Zid, Ferns
- **No Group**: Kasoon

![IAM Users and Groups Structure](https://github.com/user-attachments/assets/85ba2466-e21d-4a8d-b647-31fc20b6d5eb)

---

## IAM: Permissions

### 1. What Are Permissions?
- Users or Groups can be assigned JSON documents called policies
- Policies = rulebooks that define what actions are allowed or denied
- Actions apply to specific AWS services/resources

### 2. Example from Diagram
**Allowed actions:**
- Describe EC2 instances
- Describe Elastic Load Balancing
- List/Get/Describe CloudWatch metrics

### 3. Principle of Least Privilege
- Only give the permissions needed to perform required tasks
- Don't allow extra actions "just in case"
- **Analogy**: Give someone the key to the backseat, not the car ignition

### 4. Why It Matters
- Keeps AWS environment secure
- Prevents mistakes or misuse
- Scales well as your organization grows

![IAM Permissions Example](https://github.com/user-attachments/assets/3bcbbd64-9d4b-4b7c-9f5c-1e578e4a28ca)

---

## IAM Policies ‚Äì Inheritance

### 1. Group Permissions
- Users inherit all permissions assigned to the group(s) they belong to
- **Example:**
  - Developers group ‚Üí Alice, Bob, Charles
  - Permissions: e.g., EC2 access, S3 access
  - Everyone in that group gets the same permissions

### 2. Multiple Groups
- A user can belong to more than one group
- They inherit permissions from all groups they are in
- **Example:**
  - Charles ‚Üí Developers + DevOps Team ‚Üí gets combined permissions
  - David ‚Üí Operations + DevOps Team ‚Üí gets combined permissions

### 3. Inline Policies
- Attached directly to a specific user
- Not shared with any group
- **Example:**
  - Fred ‚Üí in Operations group + has an inline policy for extra unique permissions

### 4. Key Takeaways
- Multiple group memberships = combined permissions
- Inline policies = user-specific extra access
- **Best practice:**
  - Use groups to manage most permissions
  - Use inline policies only for special cases

![IAM Policy Inheritance](https://github.com/user-attachments/assets/d8f3ad61-aa18-4aa4-bb15-cdda2bcc667b)

---

## IAM: Policies Structure

### 1. Main Components
- **Version** (required) ‚Äì Policy language version
  - Always use: `"2012-10-17"`
- **Id** (optional) ‚Äì Identifier for the policy (e.g., name or reference)
- **Statement** (required) ‚Äì One or more blocks defining the actual permissions

### 2. Statement Components
- **Sid** (optional) ‚Äì Label or identifier for the statement
- **Effect** (required) ‚Äì `"Allow"` or `"Deny"`
- **Principal** ‚Äì Who the policy applies to (user, role, or account)
- **Action** ‚Äì List of actions the policy allows or denies
- **Resource** ‚Äì List of resources the actions apply to
- **Condition** (optional) ‚Äì Rules for when the policy is in effect (e.g., specific IP)

### 3. Example From Diagram
- **Version**: `"2012-10-17"`
- **Id**: `"S3-Account-Permissions"`
- **Principal**: AWS root account (`arn:aws:iam::1234:root`)
- **Action**: `s3:GetObject`, `s3:PutObject`
- **Resource**: `arn:aws:s3:::mybucket/*`

### 4. Key Takeaways
- A policy defines: **Who** ‚Üí Can do **what** ‚Üí On **which resources** ‚Üí Under **what conditions**
- AWS provides pre-built policies, but understanding the structure helps with custom setups

![IAM Policy Structure](https://github.com/user-attachments/assets/f55023bd-e066-4aa0-8bdd-9bdde428151f)

---

## Password Policy

You can enforce:
- A minimum password length at least 8-12 characters
- Specific requirements: caps, no caps, numbers and special characters
- Allow IAM users to change their password
- Require users to change password after some time
- Require users to not reuse same password

![Password Policy Settings](https://github.com/user-attachments/assets/0d587820-8b8d-43e5-b518-cb128129a3f4)

---

## MFA - Multi Factor Authentication

This is important because your AWS account contains important resources.

**MFA benefit**: If account password is compromised, account can't be accessed unless it has an external login. This can be done by a code, third party app or verification email.

![MFA Overview](https://github.com/user-attachments/assets/6f1bca3a-0d93-4d37-b17f-9da33de9e69b)

### MFA Options in AWS

#### Virtual MFA Device
- Virtual authenticator app e.g., Google Authenticator
- They send a one time code to access on the app on your smart phone

#### Universal 2nd Factor Security Key
- e.g., YubiKey
- It is a USB device you plug in the USB port that authenticates access without a code
- 1 key can access multiple accounts

#### Hardware Key Fob MFA Device
- Generates a code every 30 seconds
- Enter the code during log in and is a bit old school
- Good for places where electrical devices are not allowed

#### Hardware Key Fob MFA Device for AWS GovCloud
- Specifically for users in AWS GovCloud in the US

![MFA Options](https://github.com/user-attachments/assets/1d23c6ec-9b6a-476e-8435-fe1a4ef8df65)

---

## How Users Can Access AWS

### 3 Ways:
1. **AWS Management Console** - protected by password + MFA
2. **AWS CLI** - protected by keys
3. **AWS SDK** - Software Development Kit for code: protected by access keys

### Access Keys:
- Can generate keys from the console and each user manages their key
- Access keys should not be shared
- **Access Key ID** = username
- **Secret Access Key** = password

![AWS Access Methods](https://github.com/user-attachments/assets/52f6367c-8fe1-4031-9313-2bf9f692221e)

### Example of Access Key
![Access Key Example](https://github.com/user-attachments/assets/02872051-240f-474a-9e7a-a93b15a3930f)

---

## What is the AWS CLI?

The AWS CLI lets you access to the API within your AWS management console however in a CLI format. It lets you run commands and it allows you to write scripts for resource management. Used in click ops to automate jobs.

![AWS CLI Overview](https://github.com/user-attachments/assets/1ce66a20-9a56-4098-b1ec-bab5883ee678)

---

## What is the AWS SDK?

### AWS SDK ‚Äì Key Points

**What it is**: AWS Software Development Kit ‚Äì a set of pre-made code libraries for different programming languages.

**Purpose**: Lets you interact with AWS services from your code (no need to use the AWS Console).

**Languages supported**:
- Python, JavaScript, PHP, .NET, Ruby, Java, Go, Node.js, C++
- **Mobile SDKs**: Android, iOS
- **IoT SDKs**: Arduino, Embedded C, etc.

**How it works**:
- Embed AWS actions (e.g., upload to S3, create EC2) directly in your app's code
- Write just a few lines instead of doing tasks manually in the console

**Example**: The AWS CLI is built on top of the AWS SDK for Python (Boto3).

![AWS SDK Overview](https://github.com/user-attachments/assets/ce1aeda5-0271-43f3-8e61-70132d888166)

---

## IAM Roles for Services

### What are IAM Roles?
- Allow AWS services to act on your behalf without needing long-term credentials
- Provide temporary access instead of hardcoding access keys/passwords
- Improve security and flexibility

### Why use them?
- Services (like EC2, Lambda, CloudFormation) often need to interact with other AWS services
- Roles let them do this securely by attaching the right permissions

### Common Use Cases

#### EC2 Instance Roles
- Attach a role when launching an instance
- **Example**: EC2 reads/writes to S3 or DynamoDB

#### Lambda Function Roles
- Attach a role to a Lambda function
- **Example**: Lambda writes logs to CloudWatch or accesses S3

#### CloudFormation Roles
- Allows CloudFormation to create/manage resources across multiple services
- Keeps credentials secure while automating resource creation

### Key Point
- Think of IAM roles as temporary keys for services
- No hardcoded credentials
- Easy to control what permissions each service has

---

## IAM Security Tools

### IAM Credentials Report (Account Level)
A report that lists all your account's users and status of their various credentials.

### IAM Access Advisor
Shows the service permissions granted to users and when services were last accessed. You can use this info to revise your policies.

---

## IAM Guidelines and Best Practices

- Do not use root unless it's for initial account setup - use IAM user instead with correct setup
- **One physical user = one AWS user**
- Do not share logins and make sure everyone has an account
- Assign users to groups and assign permissions
- Create strong password policy
- Enforce MFA to keep account secure
- Create and use roles for giving services permissions instead of hard coding
- Use access keys for programmatic access (CLI/SDK)
- Audit permissions of your account using IAM credentials report and IAM access advisor
- **Never share IAM users or access keys**

---

## Summary

![IAM Summary](https://github.com/user-attachments/assets/87fe4c73-b8f1-489d-ace9-3f97e8216755)

---

# Amazon Compute

## Amazon EC2 

### What is EC2?
- **EC2** = Elastic Compute Cloud
- Part of AWS IaaS (Infrastructure as a Service)
- Lets you rent virtual machines (servers) from AWS
- Flexible & scalable ‚Äì used by startups and large enterprises
- Pay only for what you use

### What EC2 Helps You Do

#### Rent Virtual Machines
- Choose OS and configure as needed

#### EBS (Elastic Block Store)
- Virtual hard drive for EC2 instances
- Stores data alongside VMs

#### ELB (Elastic Load Balancer)
- Distributes incoming traffic across multiple EC2 instances
- Prevents one machine from being overloaded

#### ASG (Auto Scaling Group)
- Automatically scales instances up or down
- **Scale out** = add more instances when traffic increases
- **Scale in** = remove extra instances when traffic decreases
- Saves cost ‚Äì pay only for what's running

### Why EC2 is Important
- Core AWS service, fundamental to cloud computing
- Introduces key cloud concepts:
  - Virtual machines
  - Scaling
  - Load balancing

---

## EC2 Configurations & Options 

### 1. Operating System (OS)
- Choose from Linux, Windows, macOS, and others
- Decision depends on application requirements and what you're comfortable managing

### 2. Compute Power (CPU & Cores)
- Decide how many CPUs/cores and how powerful they should be
- **Example:**
  - Small workloads ‚Üí fewer cores
  - Heavy tasks (ML, big data) ‚Üí more cores & processing power

### 3. Memory (RAM)
- Select how much RAM the instance will have
- More RAM = better performance for large apps or real-time data processing

### 4. Storage Options
- **EBS (Elastic Block Store)**: like a hard drive attached to one VM
- **EFS (Elastic File System)**: shared storage, accessible from multiple VMs
- **Instance Store**: physical storage on the host machine. Very fast, but temporary (data lost when instance stops)

### 5. Networking
- Configure network card speed (affects traffic handling)
- Option for a public IP address (makes instance accessible from internet)

### 6. Security Groups (SGs)
- Act as firewalls for your instance
- Control who can access and what type of traffic is allowed
- Critical for securing EC2 instances

### 7. Bootstrap Script / User Data
- Script that runs automatically when the instance first launches
- Can be used to:
  - Install software
  - Run updates
  - Configure tasks

‚ö†Ô∏è **Key Point**: Right configuration matters ‚Üí prevents underperformance or overpaying for unused resources.

---

## EC2 Instance Types - Depends on What Job You Want to Do

- **General Purpose** - used for small databases, small web servers or general work loads
- **Compute Optimised** - used if lots of processing power needed, gives extra CPU for tasks like heavy computing or calculation processing
- **Memory Optimised** - used when app needs a lot of memory such as memory databases, big data processing or high performance computing work loads
- **Storage Optimised** - designed for fast and high throughput storage used for large data sets or databases that require fast processing and big storage
- **Accelerated Computing** - this is for the GPU side and is used for machine learning, video processing or scientific simulation
- **HPC Optimised** - provides high performance computing used for tasks that require a lot of processing power for intensive computing tasks and fast networking

### Naming Convention Breakdown

**AWS Instance Naming Convention (Example: M5.2xlarge)**

#### 1. Instance Class (Letter at the start)
- Tells you the purpose/type of instance
- **Examples:**
  - **M** = General Purpose
  - **C** = Compute Optimized
  - **R** = Memory Optimized
  - **T** = Burstable General Purpose

#### 2. Generation (Number after the letter)
- Shows the version/generation of the instance
- Higher number = newer, faster, more efficient
- **Example**: 5 = 5th generation

#### 3. Size (after the generation)
- Defines how big the instance is (CPU, memory, network)
- **Examples:** small, large, xlarge, 2xlarge ‚Ä¶ up to 32xlarge
- Bigger size = more resources = more cost

‚öñÔ∏è **Key Point: Choosing the Right Instance**
- Too small ‚Üí app may run out of resources, poor performance
- Too big ‚Üí wasted resources, higher costs
- **Goal** = balance performance & cost

![EC2 Instance Naming](https://github.com/user-attachments/assets/7f92149e-4311-4e9b-9a7f-e53b1d9b066d)

---

## EC2 Purchasing Options 

### üîπ On-Demand Instances
- Pay per second (no long-term commitment)
- Best for short-term, unpredictable workloads
- ‚úÖ **Example**: Testing a new app, temporary projects
- **Pros**: Flexible, predictable pricing
- **Cons**: Most expensive in the long run

### üîπ Reserved Instances (RIs)
- Commit for 1 or 3 years (longer = cheaper)
- **Types:**
  - **Standard RI** ‚Üí lowest price, fixed instance type
  - **Convertible RI** ‚Üí allows switching instance types
- ‚úÖ **Example**: Steady, long-term production workloads
- **Pros**: Big discounts
- **Cons**: Less flexible than On-Demand

### üîπ Savings Plans
- Commit to spend for 1 or 3 years
- More flexible than RIs (can apply across instance types & regions)
- ‚úÖ **Example**: Long-term use, but want flexibility
- **Pros**: Discounts + flexibility
- **Cons**: Still requires long-term commitment

### üîπ Spot Instances
- Bid for unused EC2 capacity at very low prices
- Can be terminated by AWS anytime
- ‚úÖ **Example**: Batch jobs, big data analysis, workloads that can be interrupted
- **Pros**: Cheapest option
- **Cons**: Unreliable, no guarantee of uptime

### üîπ Dedicated Hosts
- Get an entire physical server
- ‚úÖ **Example**: Compliance, software licensing tied to hardware
- **Pros**: Full control of hardware
- **Cons**: Expensive

### üîπ Dedicated Instances
- Run on hardware not shared with other customers
- ‚úÖ **Example**: Security or compliance needs
- **Pros**: Isolation from others
- **Cons**: No control over physical server itself

### üîπ Capacity Reservations
- Reserve capacity in a specific Availability Zone (AZ)
- ‚úÖ **Example**: Mission-critical workloads that must run during peak demand
- **Pros**: Guaranteed availability
- **Cons**: Pay even if not used

### ‚úÖ Quick Recommendations
- **Unpredictable workloads** ‚Üí On-Demand
- **Long-term predictable workloads** ‚Üí Reserved Instances / Savings Plans
- **Interruptible workloads** ‚Üí Spot Instances
- **Compliance/licensing needs** ‚Üí Dedicated Hosts
- **Security isolation** ‚Üí Dedicated Instances
- **Guarantee capacity in AZ** ‚Üí Capacity Reservations

---

## Security Groups & Cloud Networking 

Security groups control how traffic flows in and out of an EC2 instance. It's like firewalls however firewalls allow and deny, security groups can only allow what has been set. Anything that's not set as allowed but is allowed by default won't pass to the EC2 instance. Anything allowed on security groups for input will also be allowed for output.

**Example**: You create a website using EC2 and you allow port 80 or 443 but not SSH.

![Security Groups Basic Concept](https://github.com/user-attachments/assets/61ca939b-b422-4ff6-a725-3b942c585d74)

### Security Group Deeper Dive

They have access to ports and control which ports are open. For example, you're making a webserver and you need website traffic, you would open port 80 instead of every other port or it would cause unwanted traffic.

**Authorised IP ranges** such as IPv4 or IPv6 - this can be set to which IP has the ability to access your instance. For example, if you use an SSH login it will only allow it from an authorised IP you have set like home or office.

**Control of inbound network and control of outbound network** - controlling what your instance is allowed to do and access.

#### Table Breakdown 

**Rule 1: HTTP**
- **Protocol**: TCP (since HTTP runs over TCP)
- **Port Range**: 80 (standard HTTP port)
- **Source**: 0.0.0.0/0 ‚Üí open to the entire internet (anyone can access)
- **Meaning**: Allows inbound web traffic on port 80 from anywhere
- **Use Case**: Hosting a public website

‚ö†Ô∏è **Security Note**: Since it's open to 0.0.0.0/0, anyone can reach the server on port 80. This is normal for websites but make sure you only expose needed ports.

**üîπ Rule 2: SSH**
- **Protocol**: TCP
- **Port Range**: 22 (default SSH port)
- **Source**: 122.149.196.85/32 ‚Üí a single specific IP
- **Meaning**: Only the machine with that exact IP can connect via SSH
- **Use Case**: Secure remote admin access for one trusted user

‚úÖ **Security Best Practice**: This is a tight rule (restricted to one IP), which is good. Avoid 0.0.0.0/0 here, as that would expose SSH to the world.

**üîπ Rule 3: Custom TCP Rule**
- **Protocol**: TCP
- **Port Range**: Custom-defined (based on your app's needs)
- **Source**: Can be set to a specific IP, subnet, or 0.0.0.0/0
- **Meaning**: You open a specific TCP port for a particular application (e.g., 5000 for a Flask app, 3306 for MySQL, etc.)
- **Use Case**: Application-specific needs

‚ö†Ô∏è **Security Note**: Only open ports you absolutely need, and limit to trusted IPs whenever possible.

#### ‚úÖ Key Takeaways from the Image
- **HTTP (80)** ‚Üí Open to the world for web access
- **SSH (22)** ‚Üí Restricted to one IP for secure admin
- **Custom TCP** ‚Üí Flexible, but should be tightly controlled
- **Best Practice**: Keep rules minimal. More open = more exposure = higher risk

![Security Groups Rules Table](https://github.com/user-attachments/assets/47c0bc80-b393-4090-919a-88f088cf5515)

### Security Group Diagram 

#### 1. EC2 Instance & Security Groups
- In the center, you see an EC2 Instance with its public IP (XX.XX.XX.XX)
- Attached to it are two Security Groups:
  - **Inbound** (top box): Filters traffic coming in
  - **Outbound** (bottom box): Filters traffic going out
- Think of these SGs as firewalls at the instance level

#### 2. Inbound Rules (Top Path)
**Example from the diagram:**
- Your Computer (IP XX.XX.XX.XX) tries to connect on Port 22 (SSH)
- Since the IP + Port match the inbound rule, the SG allows it ‚úÖ
- Now you can SSH into the instance
- Another computer also tries to connect on Port 22, but its IP is not authorized
- The SG blocks this ‚ùå ‚Üí No SSH access

üëâ **Takeaway**: Inbound rules decide who can enter and on which port.

#### 3. Outbound Rules (Bottom Path)
- The instance itself may need to reach the Internet (WWW)
- Outbound SG rules decide what traffic can leave
- By default, outbound is set to any IP on any port, so:
  - The EC2 instance can download updates, fetch APIs, etc.

‚ö†Ô∏è **Best practice**: Instead of leaving "all open," restrict to required IPs/ports.

üëâ **Takeaway**: Outbound rules decide where your instance can go out to.

#### 4. Summary of Diagram
- **Inbound Security Group (SG1)**: Acts like a door guard ‚Äì lets in only specific IPs and ports
- **Outbound Security Group (SG2)**: Controls what leaves the instance ‚Äì open by default but can be tightened
- **Your Computer** (top-right): Authorized because its IP + Port 22 matches rule
- **Other Computer**: Blocked because not authorized
- **Internet** (bottom-right): Allowed outbound on any port by default

‚úÖ **Big Picture:**
- Security Groups = filters for traffic
- **Inbound**: Who can talk to your EC2
- **Outbound**: Where your EC2 can talk to outside
- **By default** ‚Üí Inbound = blocked, Outbound = open

![Security Groups Diagram](https://github.com/user-attachments/assets/101977ae-5068-423a-98bf-04ca2f17fa50)

### Security Groups Good to Know

#### 1. Reusability
- One SG can be attached to multiple instances
- Makes access management easier across many instances

#### 2. Region & VPC Bound
- SGs are tied to a specific Region + VPC
- ‚ùå You cannot use the same SG across regions or VPCs

#### 3. Where They Live
- SGs exist outside the EC2 instance
- If SG blocks traffic ‚Üí it never reaches your instance
- ‚úÖ First place to check if you can't connect to your instance

#### 4. Best Practices
- Keep a separate SG just for SSH (port 22)
- Easier to tightly control admin access without touching app/web rules

#### 5. Troubleshooting Tips
- **Timeout** (no response): Usually SG blocking traffic
- **Connection refused**: Likely an app/service issue on the instance, not SG

#### 6. Default Behavior
- **Inbound**: üö´ Blocked by default (must explicitly allow ports like 22, 80, 443)
- **Outbound**: ‚úÖ Allowed by default (instance can reach internet/others unless restricted)

SGs are reusable firewalls at the instance level. They default to blocking inbound and allowing outbound, and most connectivity issues (timeouts) are caused by SG misconfigurations.

### Security Groups Referencing 

#### 1. Normal SG Rules
- Usually, SGs allow traffic based on IP addresses + ports
- **Problem**: IPs can change (e.g., auto-scaling, dynamic environments)

#### 2. Referencing Other SGs
- Instead of IPs, you can allow traffic from another SG
- **Example in diagram:**
  - SG1 inbound rule allows traffic from SG1, SG2, SG3 on port 123
  - ‚úÖ Any instance in SG1, SG2, or SG3 can talk to the instance using SG1 on that port

#### 3. Why It's Useful
- **Dynamic scaling**: Instances come and go, but SG-based rules still work
- **Microservices:**
  - App tier SG ‚Üî Database tier SG
  - All app instances can securely talk to all DB instances
- **Simpler management**: No need to update firewall rules for changing IPs

#### 4. Key Takeaways
- SGs can reference other SGs instead of IPs
- This keeps communication secure and flexible
- **Best for:**
  - Auto-scaling groups
  - Clusters
  - Multi-tier architectures (App ‚Üî DB ‚Üî Cache)

üëâ **Easy way to remember:**
- **Normal SGs** = Lock the door by IP
- **SG referencing** = Lock the door by "group membership" instead

![Security Groups Referencing](https://github.com/user-attachments/assets/e95e177e-2279-415d-9568-2e09d09da086)

---

## Classic Ports to Know 

### üîê SSH
- **Port**: 22
- **Use**: Secure login to Linux instances
- **Tip**: Restrict access to trusted IPs only (never open to the world)

### üìÇ FTP / SFTP
- **FTP** (File Transfer Protocol): Port 21 ‚Äì insecure, being phased out
- **SFTP** (Secure FTP): Port 22 ‚Äì runs over SSH, encrypted & secure

### üåç HTTP / HTTPS
- **HTTP**: Port 80 ‚Äì Unsecured web traffic
- **HTTPS**: Port 443 ‚Äì Secured web traffic (TLS/SSL), encrypts data
- **Tip**: Always use HTTPS for sensitive apps/data

### üåê DNS
- **Port**: 53 (UDP/TCP)
- **Use**: Resolves domain names ‚Üí IP addresses
- **Critical for**: Any app that uses domain names

### üñ• RDP (Remote Desktop Protocol)
- **Port**: 3389
- **Use**: Log in to Windows instances remotely

### üìß SMTP (Simple Mail Transfer Protocol)
- **Port**: 25
- **Use**: Sending emails

### üóÑ Databases
- **MySQL**: Port 3306
- **PostgreSQL**: Port 5432

# AWS Storage and Load Balancing Guide

## Storage

### What's an EBS Volume

EBS is a network drive that can be attached to EC2 instances.

It's like a virtual storage.

It allows your instance to persist data even if it's off e.g saves data for your instances.

Bound to AZs.

Think of it like a network USB stick.

#### Why is it used

**Data persistence** - data stays in there even if an instance is terminated there will still be data saved in the EBS.

**Ideal for storing long term data** like databases.

---

## AMI Overview

### Amazon Machine Image

AMI are a customisation of EC2 instances.

You can add your own software, config, OS and monitoring.

Good if you want a faster boot config time because your software is pre packaged.

AMIs are built for specific regions but can be copied across.

**You can launch EC2 instances from:**

- **A public AMI:** AWS provided
- **Your own AMI:** make and maintain yourself
- **AWS marketplace:** AMI that someone else made and sells

---

## Amazon EFS - Elastic File System

Amazon managed solution for shared file storage.

It's a managed network file system that can be mounted onto multiple EC2 instances to share the same files.

Like a network drive that all instances can access.

EFS works with EC2 instances that are in multi AZs.

It's highly available.

Scalable - grows as the data grows.

However it is expensive and should be used when only needed.

---

# Load Balancing & Scalability

## Scalability & High Availability

Scalability means that an application/system can handle greater loads by adapting its size.

**2 Types:**

**Vertical** - when more power is added e.g upgrading a computer such as adding more ram, cpu power etc while the machine stays the same.

**Horizontal (elasticity)** - add more instances of resource to handle the workload rather than making the server bigger you add more servers to balance the workload.

Scalability is about handling greater loads.

High availability ensuring the system is up and running even parts of it fail.

### Call Center Example:

**Vertical scalability:** One person with better tools to handle more calls.

**Horizontal scalability:** Hire more people to share the workload.

**High availability (HA):** Have backups/standby staff so operations continue if someone is unavailable.

### Vertical Scalability

Means increasing the size of an instance adding storage ram and cpu power.

**Example:** If you have a t2.micro and need to upgrade you can scale and change to t2.large.

Vertical scalability is common for non distributed systems such as databases.

DBS like RDS and ElastiCache are services that can scale vertically.

There is usually a hardware limit to how much you can scale.

### Horizontal Scalability

Horizontal scalability means to increase the number of instances/systems for your application to handle more load.

Add more machines/instances based on work load.

Each machine does part of the work allowing you to handle more data.

Easier to manage if one instance fails, you have back up.

**Example:** If you have website traffic you can start more instances to handle then stop once traffic lessens.

Easy to implement and can be automated thanks to amazon services and ec2.

### High Availability

Means having multiple locations for your application/system to ensure if one part of infra fails another part can take over.

High availability and horizontal scaling go hand in hand because you need to have multiple instances across locations.

Achieve this by running applications across 2 or more AZs.

AZs are like independent data centres.

The goal of HA is to survive a data centre loss so if a data centre goes down then you have a back up to keep your app running.

<img width="681" height="340" alt="image" src="https://github.com/user-attachments/assets/f38496e3-1a71-41e6-a901-2b8616bc6dbe" />

---

## Load Balancing

### What is Load Balancing?

Load balancing is a way to distribute traffic across servers or EC2 instances.

Acts like a traffic cop distributing requests to different servers.

When traffic comes in the load balancer checks between the EC2 instances downstream to see which is up and healthy to take on more traffic.

This process keeps your application available and working just in case one instance goes down.

Load balancer will automatically divert traffic to healthy EC2 instances.

### Reverse Proxies

#### What are reverse proxies?

**Definition:**

A reverse proxy sits between users and your servers.

It handles requests on behalf of your servers.

**Similar to a Load Balancer:**

Both sit in the middle of client ‚Üî server communication.

Both can distribute traffic to servers.

**Extra Functionality (compared to Load Balancer):**

Can route traffic based on request content (e.g., URL path, headers).

Can send requests to different services or microservices.

Provides features like caching, SSL termination, authentication, compression (depending on the setup).

**AWS Example:**

Application Load Balancer (ALB) acts like a reverse proxy.

It supports content-based routing (e.g., /api ‚Üí service A, /images ‚Üí service B).

Useful in microservice architectures.

> üëâ Think of it like this:
>
> Load Balancer = Just balances traffic.
>
> Reverse Proxy = Balances traffic + adds smart routing & extra features.

<img width="299" height="198" alt="image" src="https://github.com/user-attachments/assets/dbb5b343-65be-464c-aadb-4e64f735d3e0" />

#### Why Use Load Balancer?

Spread load across multiple downstream instances prevents instances being overloaded bettering user experience.

Expose single point of access DNS to your application.

Handles failures of downstream instances redirects traffic to other healthy instances.

Does regular health checks on your instance.

Provide SSL termination HTTPS for websites load balancer deals with the heavy encryption with HTTPS websites.

Enforces stickiness with cookies - makes sure that each user is still on the same request using cookies in case they are sent back.

High availability across zones - designed to be available.

Separate public traffic from private traffic routes traffic different ways to ensure what is external or internal traffic.

### Why Use an Elastic Load Balancer

This is a managed load balancer.

AWS guarantees that it will be working.

AWS takes care of upgrades, maintenance and high availability.

AWS provides only a few configuration knobs.

#### Why DIY vs Managed Ones?

It costs less to set up your own balancer but it will be more effort you need to handle maintenance monitoring scaling and fault tolerance on your own.

With ELB AWS manages all that complexity.

#### Key AWS Services ELB integrates with:

**Amazon Certificate Manager (ACM):**

Handles SSL/TLS certificates.

ELB can terminate SSL for you (removes complexity).

**Amazon CloudWatch:**

Monitor ELB performance and health.

**Amazon Route 53:**

DNS routing integrated with ELB.

**AWS WAF (Web Application Firewall):**

Protects apps from attacks (SQL injection, XSS, etc.).

**AWS Global Accelerator:**

Improves performance and reliability for global traffic.

#### Why Use ELB?

**Reliable & Low-Maintenance** ‚Üí AWS manages availability.

**Time-Saving** ‚Üí No need to build/maintain your own load balancer.

**Scalable** ‚Üí Works with Auto Scaling seamlessly.

**More costly** than DIY solutions, but saves effort and operational overhead.

### Health Checks

Key part of load balancing.

They allow the load balancer to know if instances are good enough to handle traffic and it is done via requests.

A request is sent to a HTTP protocol on any port then to the end point.

The health check is done on a port and a route (/health is common).

If the response is not 200 being OK then the instance is unhealthy.

If 200 is returned then it's considered healthy.

<img width="475" height="161" alt="image" src="https://github.com/user-attachments/assets/cd7b7aa4-646d-4820-bc94-5646b67f6291" />

---

## Types of Load Balancers on AWS

There are 4 kinds:

### Classic Load Balancer (v1 generation) 2009 - CLB

Handles the basics HTTP, HTTPS, TCP, SSL.

Gets the job done.

Lacks new generation features.

### Application Load Balancer (v2 new gen) 2016 - ALB

HTTP, HTTPS, WebSocket.

Ideal for modern apps.

Works on the application layer.

Smarter able to direct traffic based on requests like URLs headers clear parameters and cookies.

Perfect for microservices or containers that need routing.

### Network Load Balancer (v2 - new gen) - 2017 NLB

TCP TLS, UDP.

Layer 4 Load Balancer.

Designed for high performance scenarios where low latency is needed.

Ideal for handling millions of requests per second.

Used for low latency applications e.g for real time gaming or high frequency trading systems.

### Gateway Load Balancer - 2020 - GWLB

Operates at layer 3 network layer - IP protocol.

Helps deploy scale and manage third party network applications like firewalls intrusion detection systems and traffic analysers in your VPC.

---

## Which AWS Load Balancer Should I Choose?

### Classic Load Balancer (CLB)

Still works but old generation.

Limited features.

AWS recommends using ALB, NLB, or Gateway LB instead.

### Internal vs External

**Internal LB:** Routes traffic inside your VPC (e.g., microservices, private apps).

**External LB:** Handles traffic from the public internet (e.g., websites, APIs).

### Recommended Load Balancers

#### Application Load Balancer (ALB)

**Best for:** Web applications.

**Features:**

Content-based routing (e.g., /api ‚Üí service A, /images ‚Üí service B).

Supports modern protocols (HTTP/2, WebSockets).

Good for microservices & container-based apps.

#### Network Load Balancer (NLB)

**Best for:** High-performance, low-latency TCP/UDP traffic.

**Features:**

Handles millions of requests per second.

Very low latency.

Ideal for gaming servers, IoT, VoIP, or real-time apps.

#### Gateway Load Balancer (GWLB)

**Best for:** Advanced network applications.

**Features:**

Routes traffic to third-party appliances (e.g., firewalls, intrusion detection, deep packet inspection).

Useful in secure network setups.

> üëâ Quick Decision Guide:
>
> Traditional web app? ‚Üí ALB
>
> Need ultra-fast TCP/UDP performance? ‚Üí NLB
>
> Advanced networking (firewalls, IDS, etc.)? ‚Üí GWLB
>
> Old system? ‚Üí Only then use CLB (otherwise avoid).

---

## Load Balancer Security Groups

### Load Balancer Security Group

**Purpose:** Expose the application to the internet safely.

**Rules:**

Allows HTTP (TCP, port 80) from 0.0.0.0/0 ‚Üí anyone on the internet.

Allows HTTPS (TCP, port 443) from 0.0.0.0/0 ‚Üí anyone on the internet.

**Effect:** Users can reach the load balancer using either HTTP or HTTPS.

**Key point:** The load balancer is the only public-facing component.

### Application Security Group (EC2/Instances behind LB)

**Purpose:** Protect backend EC2/Istio instances.

**Rules:**

Allows HTTP (TCP, port 80), but only from the Load Balancer SG (not from the public internet).

In the example, the source is set to the load balancer's SG (sg-054b5ff5ea02f2b6e).

**Effect:** The backend instances will not accept traffic directly from users. They only trust requests forwarded by the load balancer.

### Why This Works (Analogy)

Think of it as:

**Load Balancer** = Front Door ‚Üí Anyone can knock on it (open to the internet).

**Application Servers** = Private Rooms ‚Üí Only the front door (LB) has the key; strangers can't walk in directly.

This design ensures:

‚úÖ **Security** ‚Äì Backends aren't exposed to direct attacks from the internet.

‚úÖ **Scalability** ‚Äì Load balancer can distribute traffic evenly to multiple instances.

‚úÖ **Flexibility** ‚Äì You can apply SSL termination, routing, or WAF (firewall rules) at the load balancer level.

<img width="770" height="388" alt="image" src="https://github.com/user-attachments/assets/82a22a67-d3e3-4627-8a97-caf3643d7bfd" />

---

## Application Load Balancer

### Application Load Balancer (ALB) Notes + Examples

**ALB operates at layer 7 HTTP layer**

Example: it can inspect HTTP headers to decide routing, unlike a Classic Load Balancer which only works at TCP level.

**Smart enough to understand what is being requested** such as headers, cookies, URLs, strings and more

Example: a request with Cookie: user=premium could be routed to a premium server pool.

**Load balance traffic to multiple HTTP applications across machines**

Example: spreading traffic across 3 EC2 instances running the same web app so no single machine gets overloaded.

**Load balance to multiple applications on the same machine**

Example: one EC2 runs /app1 (Node.js) on port 3000 and /app2 (Flask) on port 4000 ‚Äî ALB routes to the correct one.

**Has support for HTTP/2 and WebSocket**

Example: useful for chat apps needing WebSocket connections or faster loading with HTTP/2 multiplexing.

**Supports redirects from HTTP to HTTPS as an example**

Example: http://myshop.com automatically redirects to https://myshop.com.

**Routing tables to different target groups**

Example: /images/* ‚Üí servers optimized for images, /api/* ‚Üí backend servers.

**Route based on path in URL**

Example: /blog/* goes to blog servers, /shop/* goes to e-commerce servers.

**Routing based on host name in URL**

Example: api.myapp.com ‚Üí API target group, admin.myapp.com ‚Üí admin dashboard.

**Routing based on query string, headers**

Example: ?category=toys ‚Üí toy catalog servers, X-Region: EU header ‚Üí EU servers.

**ALB are a great fit for microservices & container based applications** e.g. Docker & Amazon ECS

Example: each ECS service (auth, payments, users) gets its own target group, ALB directs requests correctly.

**Has a port mapping feature to redirect to dynamic port in ECS**

Example: ECS assigns random container ports (32768, 32769, etc.), ALB maps incoming traffic automatically.

**In comparison we need multiple classic load balancers per application**

Example: 3 microservices (/auth, /cart, /profile) would need 3 CLBs, but only 1 ALB with routing rules.

### How ALB Handles HTTP Based Traffic

**Users send HTTP requests** ‚Üí ALB sits in front of the application and receives the traffic.

**ALB examines each request** ‚Üí decides where to route based on rules (path, host, headers, etc.).

**Routes traffic to Target Groups:**

A target group = a collection of resources (EC2, ECS tasks, or Lambda).

Each target group usually supports a specific service.

Example: one target group for user-related tasks (login, profile).

Another for product search or other functionality.

**Health Checks:**

ALB continuously runs health checks on targets.

If an instance fails health checks, ALB automatically stops sending traffic to it and routes requests to healthy ones.

**Built for HTTP/HTTPS traffic:**

Can handle many web-based services.

Smart enough to separate traffic by path, hostname, or query.

#### Why this matters:

You can route different requests to different parts of your application using one ALB.

**Example:**

https://example.com/profile ‚Üí routes to User Service Target Group.

https://example.com/search ‚Üí routes to Search Service Target Group.

**Benefit:**

Keeps services separate so one doesn't interfere with the other.

Makes scaling and performance much easier (great for microservices).

<img width="547" height="307" alt="image" src="https://github.com/user-attachments/assets/189c5ef9-ca01-478e-9db1-de8316096a09" />

---

## Application Load Balancer (Target Groups)

### What are target groups

Target groups are groups of resources like EC2 Lambda functions and ECS tasks that your ALB routes traffic to.

They are destination for requests that a load balancer handles.

Each target group is tied to certain parts of an application allowing scalability of your system independently.

### Different target groups

**EC2 instances** (can be managed by an auto scaling group) - HTTP

**ECS tasks** (managed by ECS) - HTTP

**Lambda functions** - HTTP request is translated into a JSON event

**IP addresses** - must be private IPs

ALB can check route to multiple target groups.

Health checks are at the target group level.

### ALB good to know

Has a fixed host name provided by AWS.

The application servers don't see the IP of the client directly.

The true IP of the client is inserted in the header X-Forwarded-For.

We can also get Port (X-Forwarded-Port) and proto (X-Forwarded-Proto).

<img width="622" height="175" alt="image" src="https://github.com/user-attachments/assets/80cbebdc-cf9d-4b18-947a-483692779452" />

---

## Network Load Balancers

Optimised for handling extreme performance with low latency.

Works on the network layer layer 4.

Forward TCP & UDP traffic to your instances.

Handle millions of requests per seconds.

Less latency - 100ms compared to ALB which has 400ms.

NLB has one static IP per AZ and supports assigning Elastic IP.

NLB are used for extreme performance TCP or UDP traffic.

Not included in AWS free tier.

Used for stuff like IoT gaming Real time processing.

### Network Load Balanced with TCP Traffic

Works at layer 4 and routes raw TCP or UDP traffic to instances without getting involved with higher level traffic like HTTP and HTTPS.

#### How Traffic is Routed

**Incoming Request (WWW)** ‚Üí Enters NLB with TCP rules.

**NLB forwards traffic to a Target Group:**

**Users Application** ‚Üí Uses TCP rules.

**Search Application** ‚Üí Uses HTTP (inside TCP).

#### Key Points About NLB

**Does not:**

Inspect HTTP headers.

Do SSL termination (no HTTPS handling at Layer 7).

Only forwards traffic fast and efficiently without changing it.

#### When to Use NLB

‚úÖ **Best for raw performance and low latency.**

‚úÖ **Can handle millions of requests per second.**

‚úÖ **Ideal for:**

Real-time apps (gaming, streaming, chat, etc.).

Applications sensitive to latency and connection speed.

‚úÖ **Good when different apps use different protocols (TCP vs HTTP).**

#### NLB vs ALB

**NLB (Layer 4):** Speed, raw TCP/UDP forwarding.

**ALB (Layer 7):** Understands HTTP/HTTPS, can do SSL termination, read headers, smarter routing.

> üëâ **Summary:**
>
> The NLB is like a super-fast traffic cop at the network layer. It doesn't "look inside" the traffic (like ALB would), it just forwards TCP/UDP connections to the right target group based on rules. Great for performance-heavy apps needing speed and scalability.

<img width="767" height="322" alt="image" src="https://github.com/user-attachments/assets/b7214f2f-4350-4f81-a65a-00bcdfe08f03" />

---

## Sticky Sessions (Session Affinity)

Sticky sessions ensure the client or user is routed to the same instance behind the load balancer.

Works across different load balancers.

The load balancer uses a cookie to keep track of which instance a client is connected to.

Each cookie binds a user to a certain server.

You can control their time and expiration.

A use case when an application store session data that is not shared across instances.

Makes sure session data is not lost.

For example a cart cookie on an e commerce site since this is a separate instance a cookie will make sure the user doesn't lose their cart data.

May bring imbalance to the load over the back end of instances.

Use if needed.

---

## SSL/TLS Basics

Crucial when dealing with internet security with load balancers.

SSL cert allows traffic between your clients/users and load balancer to be encrypted in transit (in-flight-encryption).

SSL refers to secure sockets layer, used to encrypt connections.

TLS refers to transport Layer security which is a newer version.

Nowadays TLS certificates are mainly used but people still refer to it as TLS.

Public SSL certs are issued by Certificate authorities such as Comodo, Symantec, GoDaddy, Global Sign etc.

SSL certifications have expiration dates you set and must be renewed.

### Load Balancer - SSL Certificates

Load balancer uses a X509 cert SSL certificate.

AWS allows us to manage this using their certificate manager ACM.

ACM is a place where you can create renew and manage certificates.

You can upload your own certificates.

**HTTPS Listener:**

This is how we ensure traffic is encrypted.

You must specify default certificate.

You can add an optional list of certs to support multiple domains.

Clients can use SNI server name indication to specify the host name they reach.

Can specify security policies to support older versions of SSL clients.

### SSL - SNI Server Name Indication

SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites).

It's a newer protocol and requires the client to indicate the host name of the target server in the initial SSL handshake.

The server will then find the correct certificate or return the default one.

Only works for ALB and NLB new gen, CloudFront.

Does not work for CLB old gen.

### ELB - SSL How Do They Work on Different Load Balancers

#### CLB - Classic Load Balancer v2

Supports only one SSL cert.

Must use multiple CLB for multiple host name with multiple SSL certificates.

#### ALB Application Load Balancer v2

Supports multiple listener with multiple SSL certificates.

Uses server name indication SNI to make it work.

#### Network Load Balancer V2

Supports multiple listeners with multiple SSL certs.

Uses server name indication SNI to make it work.

---

## Connection Draining

**Purpose:** Prevents cutting off ongoing user requests when removing an instance from a load balancer.

**Terminology:**

Classic Load Balancer (CLB) ‚Üí Connection Draining

Application Load Balancer (ALB) & Network Load Balancer (NLB) ‚Üí Deregistration Delay

### How it Works

When an instance is deregistered (unhealthy, scaling down, etc.):

The load balancer stops sending new requests to that instance.

Any in-flight requests (already connected) are allowed to complete.

### Timing Control

Can set the wait time: 1‚Äì3,600 seconds (default = 300 seconds = 5 minutes).

**Use Cases:**

Short requests ‚Üí Set lower value to speed up removal.

Instant removal ‚Üí Set to 0.

Long-running requests ‚Üí Keep higher value to avoid user disruption.

‚úÖ **Key Benefit:** Ensures smooth user experience during scaling or instance health changes by letting active sessions finish before removal.

---

## Auto Scaling Groups

### What is an Auto Scaling Group ASG

In real life the load on your application and website can change.

In the cloud you can create and get rid of servers very quickly.

**The goal of ASG:**

Scale out add EC2 instance to match increase load.

Scale in remove EC2 instances to match decrease load.

Ensure there is a min and max of EC2 instances running.

Auto register new instances to a load balancer.

Re create an EC2 instance in case a previous one is terminated.

ASG is free you only pay for the EC2 instance.

### Auto Scaling Group

üìå **Key Settings:**

#### Minimum Capacity

The fewest instances that must always run.

Ensures your app is always available, even during low traffic.

#### Desired Capacity

The "target" number of instances for normal load.

ASG tries to keep this number steady under typical conditions.

#### Maximum Capacity

The upper limit of instances ASG can create.

Prevents overspending and unnecessary scaling.

### Scaling Behavior

#### Scale Out (Traffic ‚Üë)

ASG adds new EC2 instances when demand rises.

Can scale up until it reaches the maximum capacity.

#### Scale In (Traffic ‚Üì)

ASG removes instances when demand drops.

Reduces costs but never goes below the minimum capacity.

‚úÖ **Result:**

ASGs automatically balance performance and cost:

Keep enough instances running for reliability.

Add instances during spikes.

Remove them when demand falls.

### Auto Scaling Group in AWS with Load Balancer

#### 1. Users

Send traffic to your application (website, mobile app, or service).

#### 2. Elastic Load Balancer (ELB / ALB)

Distributes traffic evenly across EC2 instances.

Prevents overload on any single instance.

**Performs health checks:**

Continuously monitors EC2 instances.

If an instance is unhealthy ‚Üí stops sending traffic to it.

Once fixed/replaced ‚Üí resumes routing traffic.

#### 3. Auto Scaling Group (ASG)

Automatically adjusts the number of instances based on demand.

Scale Out ‚Üí adds instances during high traffic (e.g., sales day).

Scale In ‚Üí reduces instances when traffic drops to save costs.

Works with the ELB to ensure only healthy instances serve traffic.

#### 4. Amazon Machine Image (AMI)

Custom AMIs can be used to launch preconfigured instances.

Every new instance created by ASG is ready-to-go with:

Your software

Configurations

Dependencies

‚úÖ **Big Picture:**

**Load Balancer** = smart traffic director.

**ASG** = dynamic capacity manager.

**AMI** = ensures consistency across all instances.

**Together** ‚Üí they create a scalable, fault-tolerant, and cost-efficient system.

<img width="670" height="318" alt="image" src="https://github.com/user-attachments/assets/836935b6-7075-414d-aaf3-d00fbca605f8" />

---

## Auto Scaling Group Attributes

### Launch Template includes:

**AMI** ‚Üí Pre-configured Amazon Machine Image (ensures all EC2s start with same setup).

**Instance Type** ‚Üí Defines resources (CPU, memory, storage capacity).

**EBS Volumes** ‚Üí Persistent storage attached to EC2s.

**Security Groups** ‚Üí Virtual firewalls for inbound/outbound traffic.

**SSH Key Pair** ‚Üí Secure login credentials for EC2 access.

**IAM Role** ‚Üí Grants EC2 permissions to use AWS services securely.

**VPC + Subnets** ‚Üí Network placement for instances.

**Load Balancer** ‚Üí Registers instances for traffic distribution.

### Other ASG attributes:

**Min Size / Max Size / Initial Capacity** ‚Üí Controls number of running instances.

**Scaling Policies** ‚Üí Rules that tell ASG when to scale in/out based on demand.

<img width="208" height="241" alt="image" src="https://github.com/user-attachments/assets/4f5d8424-962e-43bb-ba0e-2a4633a4d013" />

---

## Auto Scaling - CloudWatch Alarms & Scaling

CloudWatch alarms keep an eye on certain metrics across ASG like power and CPU usage or a custom metric.

Once alarm is triggered AWS can take action.

You can use scaling policies such as scale out and scale in which increase and decrease instances.

### Auto Scaling Group Scaling Policies

#### Dynamic Scaling

##### Target Tracking Scaling

Simple to set up.

Example: I want the average ASG usage CPU usage to stay around 40%.

##### Simple/Step Scaling

When CloudWatch alarm is triggered example CPU > 70% add 2 units.

When CloudWatch alarm is triggered example CPU < 30% then remove 1.

#### Schedule Scaling

Anticipate a scaling based on known usage patterns.

Example: increase the min capacity to 10 at 5pm on Fridays.

## containers
Docker recap 
Docker = a platform to build, ship, and run apps in a consistent way.

Packages everything your app needs (code, libraries, dependencies, runtime) into a container.

Runs the same everywhere: laptop, server, or cloud.

What is a Container?

A lightweight, portable box holding:

App code

Libraries & dependencies

Runtime environment

Ensures the app behaves the same across all systems.

Solves the classic ‚Äúworks on my machine‚Äù problem.

Why Use Docker?

Portability ‚Äì works on any system with Docker installed.

Consistency ‚Äì same behavior in dev, staging, production.

Speed ‚Äì starts fast, uses fewer resources than VMs.

Simplicity ‚Äì everything bundled and easy to ship/deploy.

How Docker Works

Container Image = blueprint of the app (code + dependencies).

Container = running instance of that image.

Works across:

Local servers

Cloud environments

Other machines

Docker on an opperating system 
1. Server (the big box)

Could be an EC2 instance, local machine, or any host.

Runs the Docker Engine (container runtime).

2. Containers (the smaller boxes inside)

Each container runs one application with its own dependencies.

Examples shown in the diagram:

Java apps (multiple versions or instances)

Nginx web server

MySQL database

3. Key Points from the Diagram

Isolation: Each app is in its own container, no interference between Java, Nginx, or MySQL.

Shared host resources: All containers use the same host OS kernel, CPU, memory, and networking.

Multiple instances: You can run multiple versions of the same app (e.g., 3 Java containers) without conflicts.

Lightweight: Unlike VMs, containers don‚Äôt need their own OS ‚Äî they share the host‚Äôs OS kernel.
<img width="474" height="343" alt="image" src="https://github.com/user-attachments/assets/9a3c67c3-54b5-4ff7-a3fe-2a2d01a97708" />

whewre are docker images stored 
Docker Images Recap

Docker Image = a blueprint for your app.

Contains code, libraries, dependencies, configs.

Once built ‚Üí can run as a container.

Where Are Images Stored? ‚Üí Repositories

A repository = folder for Docker images.

Can be public or private.

1. Docker Hub

Largest public repo for Docker images.

Like GitHub for Docker images.

Hosts base images (Ubuntu, Nginx, MySQL, etc.).

Anyone can push or pull images.

2. Amazon ECR (Elastic Container Registry)

AWS-managed repository.

Designed for AWS users.

Stores images securely (private by default).

Can also publish images publicly via ECR Public Gallery.

Integrates with other AWS services (ECS, EKS, etc.).

Public vs. Private Repositories

Public repos (e.g., Docker Hub, ECR Public):

Anyone can access/download images.

Good for sharing or using common base images.

Private repos (e.g., ECR Private):

Restricted access (only authorized users).

Used by organizations to control security & access.

üëâ Summary:

Build image ‚Üí store in a repo (public or private).

Docker Hub = biggest public repo.

Amazon ECR = secure, AWS-focused repo with private + public options.

docker vs virtual machines 
Virtual Machines (VMs)

What they are: Full virtual systems that mimic physical hardware.

Components:

Each VM has its own guest OS (Ubuntu, Windows, etc.).

Managed by a hypervisor (e.g., VMware, Hyper-V).

Resources: Each VM gets its own chunk of CPU, RAM, storage.

Downsides:

Heavy ‚Üí each VM carries a full OS.

Slow boot times.

High resource usage.

Containers (Docker)

What they are: Lightweight, OS-level virtualization.

Components:

Share the host OS kernel.

Managed by the Docker daemon (lighter than a hypervisor).

Resources: Multiple containers run side-by-side, each with its own app + dependencies.

Benefits:

Fast start/stop times.

Lightweight ‚Üí no extra OS per container.

Portable ‚Üí run anywhere Docker is installed.

Efficient ‚Üí run many more containers per server compared to VMs.

Key Difference

VMs ‚Üí Virtualize hardware (each has its own OS).

Containers ‚Üí Virtualize the OS (apps isolated but share same kernel).
<img width="500" height="223" alt="image" src="https://github.com/user-attachments/assets/ea0cf5c9-198c-4e0a-9d4e-372920ea8278" />

getting styaryed with docker 
1. Dockerfile ‚Üí The Recipe

Defines how to build your Docker image.

Common instructions:

FROM ‚Üí base image (e.g., ubuntu:18.04).

COPY ‚Üí copy app files into the image.

RUN ‚Üí run commands during build (install deps, compile).

CMD ‚Üí default command when container starts (e.g., run Python script).

2. Build the Image

Command:

docker build -t myapp .


This takes the Dockerfile ‚Üí produces an image.

Image = blueprint you can reuse to start containers.

3. Run the Container

Command:

docker run myapp


This creates a container = running instance of your image.

Example: container running a Python application.

4. Push & Pull Images

Push images to a registry (cloud storage for images).

Docker Hub (public repo).

Amazon ECR (private/public repo for AWS).

Pull them later to use anywhere (local, servers, cloud).

üîë Summary Flow

Dockerfile (blueprint) ‚Üí Build (Image) ‚Üí Run (Container) ‚Üí Push/Pull (Registry like Docker Hub / ECR)

<img width="502" height="251" alt="image" src="https://github.com/user-attachments/assets/e489e36c-2ded-4964-9b8a-4b581ae3862b" />


conatiner related services 
Amazon elastic container service ECS
amazons own platform
fully managed service that a\llows you to run docker containers without having to install and manage orchastration software
you can define conatiner number, images to use, how they should interact througha  simple interface 

elastic kubermetes service amazon EKS
amazon managed kubernetes 
with EKS you can take advantage 

aws fargate amazon own serverless containe rplatfoprm
works with ecs and eks

amazon ecr 
stiores container images 

amazon ECS - EC2 launch type
ECS elastic container services 
launch docker container on aws = lauch ecs tasks on ecs clusters
ec2 launch type: you must provision abd nmain tain the infrastructure (the ec2 instances)
Each ec2 instance must trun the ECS agent to register in the ecs cluster
AWS takes care if starting/stopping containers 
<img width="322" height="316" alt="image" src="https://github.com/user-attachments/assets/8c66c9fd-d269-4055-a723-8119c881b928" />

amazon ecs fargate launch type
Launch docker containers on AWS
you do not provision the infrastructure no ec2 instances to manage 
its all serverless
yopu just create task defenitions
AWS just runs ECS tasks for you based on the CPU / RAM you need 
To clase, just increassee the number of tasks simple- no more ec2 instance tasks 

amazon ecs IAM roles for ECS
Used by tge ECS agent 
makes API xcales to ECS servuce 
Send container logs to cloudwatch logs 
Pull dcker imaghe from ECR
Reference sensitive data in secreyts 
manager ort SSM poarameter store 

ecs TASK ROLE
ALLOWS EACH TASK TO HAVE A SP[ECIFIC ROLE
USE DIFFERENT ROLES FOR TTHR DIFFERENT ecs SERVBICES YOU RIN 
tASK ROLE IS DEFINED IN THE TASK DEFENITION 

<img width="353" height="367" alt="image" src="https://github.com/user-attachments/assets/0369381e-3e64-49b4-9583-a8aa8fcd28cb" />

amazon ECS load balancer intigration 
Application load balancer supported and works for most use cases the go to choice as it operates at layer 7
worksz with https/http 
supports path based routing 

NLB reccomended for high performamve or to pair with AWS provate link ddoesnt have advance feature

CLB supported not recommended used for lgacy systems 
<img width="330" height="364" alt="image" src="https://github.com/user-attachments/assets/f65a601f-6bea-4056-8bd3-5babbdb76ee4" />

ECS service autoi scalling
üîπ What is ECS Service Auto Scaling?

Automatically adjusts the number of ECS tasks running based on demand.

Scales up when traffic/CPU goes up.

Scales down when things calm down ‚Üí saves money.

Uses AWS Application Auto Scaling under the hood.

üîπ Metrics Used for Scaling

CPU utilization

Memory utilization

ALB (Application Load Balancer) request count per target

Other custom CloudWatch metrics

üîπ Scaling Strategies

Target Tracking (simple & dynamic)

Set a target (e.g., keep CPU at 40%).

AWS automatically adjusts tasks to maintain that target.

Easiest to use.

Step Scaling (fine-grained control)

Define thresholds and actions:

If CPU > 70% ‚Üí add 2 tasks.

If CPU < 30% ‚Üí remove 1 task.

More manual but gives full control.

Scheduled Scaling (predictable traffic)

Pre-plan scaling events.

Example: If traffic spikes every Tuesday 5 PM ‚Üí scale up before, scale down after.

üîπ ECS with Fargate

No need to manage EC2 instances.

You only define how many tasks you want.

AWS manages infrastructure scaling for you.

‚úÖ Summary

ECS auto scaling = handles spikes, saves costs.

Options: Target Tracking (simple), Step Scaling (precise), Scheduled Scaling (predictable).

Even easier with Fargate since AWS manages the servers.

amazon ECR 
What is ECR?

Cloud storage system for Docker images.

Works like a container image hub (similar to Docker Hub but on AWS).

Designed to integrate directly with ECS.

Stores images securely (backed by Amazon S3).

üîπ Types of Repositories

Private Repositories

Store internal/sensitive Docker images.

Access controlled by IAM.

Public Repositories

For open-source or shared images.

Amazon ECR Public Gallery provides free/public images.

üîπ ECS Integration

ECS tasks can pull images directly from ECR.

Makes deployment smooth and automatic.

üîπ Security & Access

Permissions controlled with IAM policies.

Common issue: if pulling fails ‚Üí check IAM permissions.

üîπ Extra Features

Vulnerability Scanning ‚Üí scans images for security risks.

Versioning & Tagging ‚Üí manage multiple image versions (e.g., v1.0, latest).

Lifecycle Management ‚Üí automatically deletes old images to save space.

‚úÖ Summary:
ECR = secure, scalable Docker image storage on AWS. Integrated with ECS, controlled by IAM, with extra features like scanning, versioning, and lifecycle cleanup.
<img width="200" height="369" alt="image" src="https://github.com/user-attachments/assets/83b4f707-f144-40be-b5b5-8b323ffa303e" />

Amazon EKS 
What is EKS?

Fully managed Kubernetes service on AWS.

AWS manages the control plane (updates, patching, scaling).

You just focus on running apps, not cluster management.

üîπ Why Kubernetes?

Open-source container orchestration platform.

Automates deployment, scaling, and management of containers.

Helps run containers at scale.

üîπ EKS vs ECS

ECS (Elastic Container Service)

AWS-specific, simpler API.

Deep integration with AWS services.

EKS (Elastic Kubernetes Service)

Based on Kubernetes (open-source, cloud agnostic).

Easier migration between AWS, GCP, Azure (AKS), or on-prem.

Ideal if you already use Kubernetes elsewhere.

üîπ Launch Types in EKS

EC2 Launch Type ‚Üí You manage worker nodes (EC2), AWS manages control plane.

Fargate Launch Type ‚Üí Serverless, AWS runs the containers, no need to manage EC2.

üîπ Use Cases

Migrating from on-prem or another cloud while keeping Kubernetes.

Running workloads across multiple clouds (cloud agnostic).

Multi-region deployments ‚Üí 1 EKS cluster per region.

üîπ Monitoring & Insights

Integrated with CloudWatch Container Insights.

Tracks logs, metrics, performance.

Helps troubleshoot & optimize workloads.


EKS diagram 
EKS Architecture (based on the diagram)
üîπ Core Components

EKS Worker Nodes

The yellow boxes = EC2 instances running Kubernetes worker processes.

These nodes actually run your pods (smallest unit in Kubernetes).

Pods

Groups of containers that perform specific tasks.

Hosted inside the worker nodes.

Auto Scaling Group (ASG)

Worker nodes are part of an ASG.

Scales nodes up/down automatically based on load.

üîπ Networking & Security (VPC setup)

VPC (Virtual Private Cloud)

Isolated private network where the entire EKS setup runs.

Ensures secure communication between components.

AZs (Availability Zones)

Multiple AZs used for high availability.

If one AZ goes down, others keep the app running.

Private Subnets

Worker nodes are deployed here for security.

Not directly exposed to the public internet.

NAT Gateway

One in each AZ.

Lets worker nodes access the internet outbound (e.g., to pull Docker images, updates).

Prevents inbound public traffic from reaching nodes directly.

üîπ Traffic Management

ELB (Elastic Load Balancer)

Distributes incoming user traffic across nodes.

Sends requests to healthy nodes only.

Improves performance + fault tolerance.

üîπ Why Multiple AZs?

Provides resilience & fault tolerance.

If one AZ fails, traffic is routed to nodes in other AZs.

Keeps the application always available.

‚úÖ Summary

This architecture is a secure, scalable, highly available setup for Kubernetes on AWS.

EKS nodes + pods ‚Üí Run your workloads.

ELB ‚Üí Balances user traffic.

NAT Gateways ‚Üí Allow safe outbound internet access.

VPC + private subnets ‚Üí Provide security and isolation.

Multiple AZs ‚Üí Ensure uptime even if one zone fails.

<img width="758" height="365" alt="image" src="https://github.com/user-attachments/assets/6e28614a-2f0c-4ace-9a2d-c0d4c80363b4" />

amazon eks nonde types 
managed node groups
creates and manages nodes 9EC2 instance for you
nondes are apart of an ASG managed by EKS
supports on demand oir spot instances 

self managed nondes 
nodes created by you and register to thee EKS cluster and manged by ASG 
you can use prebuilt AMI amazon EKS optomised AMI
support on demand or spot instances

AWS fargate 
no mantinence requirewd no nones managed its serrverless all you need to do is define cpu and memory requirments for containers 

##Serverless
Serverless overvbiew 
serverless is when develiops dont have to manage servers anymore 
they just deploy code 
they deploy functions 
serverless is a FAAS fdunction as a service 
serverless was pioneered by AWS lambda but noe includes anyhhingthing that managed 
serverless does not mean rhere are no serevers
it means you dont manage provision or see them 

serverles in aws 
lambda us the core of servereless offerings
you just write your functions deploy the lambda function and it does the job 
dynamoDB - fully managed serverless nosql data basethats scales automaticlly
cognito - shelps manage user authentication easier to handle logins and signups on applications
api gateway - acts like a bridge between users and ;ambas functions you can create and monitor apis which interact with yout back end services
S3 - serveress offering for storing files and conetent
SNS & SQS SNS handles nototficatrionsd SQS queues messaging between services they are messaging systems 
Kineses data fire hose - used to lower streaming data in tghe AWS dfor analysis and storage 
AUror serverless - fully managed serverless data basew theat auto scales on demand
step functions - step functions helps you manage multiple lambda functions 
fargate - serverless compute option AWS handles your ec2 instances 

<img width="226" height="270" alt="image" src="https://github.com/user-attachments/assets/dc42629a-d581-4636-9d46-86a51f346076" />

why aws lambda 
Why Use AWS Lambda?
üîπ EC2 (Elastic Compute Cloud)

Virtual servers (VMs) in the cloud.

You choose CPU & memory for each instance.

Always running ‚Üí you pay even when idle.

Scaling requires manual setup (or auto scaling configs).

Good for long-running applications or when you need full control.

üîπ Lambda (Serverless Functions)

No servers to manage ‚Üí AWS handles it.

Runs on-demand, only when triggered.

Billed only for execution time (no idle cost).

Execution limit ‚Üí max 15 minutes per function.

Best for short, event-driven tasks (e.g., S3 upload trigger, API call, stream processing).

Automatic scaling ‚Üí handles 1 to 1M+ requests seamlessly.

‚úÖ Summary

EC2 = Full control, but you manage servers, scaling, and costs (can pay for idle).

Lambda = Serverless, auto-scaling, cost-efficient, but limited to short-lived, event-driven workloads.


benefits of lambda 
easy pricing - pay fopr what you use
free tier gve 1000000 requests and 4000000Gb of compoute time
intigrated wuth the whole aws suite of services
integrated with many programming manguages 
easy monitoringh through cloudwatch
easy to get more resources per functions
increasing ram will improves CPU and network

üîπ Built-in Supported Languages

Node.js (JavaScript) ‚Üí great for event-driven apps.

Python ‚Üí widely used for data processing, automation, serverless web apps.

Java ‚Üí popular for enterprise-level apps.

C#, .NET Core, PowerShell ‚Üí strong fit for Microsoft developer background.

Ruby ‚Üí good for scalable web apps (e.g., with Rails).

üîπ Custom Runtimes

Use the Lambda Runtime API to bring your own language.

Example: Go (Golang) and other non-officially supported languages.

Lets you choose a language that fits your project best.

üîπ Lambda Container Images

Package your app into a Docker container image.

Ideal for:

Complex app setups.

Custom dependencies.

More control over runtime environment.

Requirement: container must implement Lambda Runtime API.

üëâ If you want full flexibility with Docker containers (beyond Lambda limits), use ECS Fargate instead.

‚úÖ Summary

AWS Lambda supports multiple languages out-of-the-box, plus custom runtimes and container images for flexibility. This means you can run serverless functions in the language and environment you‚Äôre most comfortable with.

example of serveerlsss
Example: Serverless Thumbnail Creation
üîπ Flow of Events

Upload Image to S3

User uploads an image (e.g., beach photo) to an S3 bucket.

This is the starting point.

Trigger Event

The S3 upload event automatically triggers a Lambda function.

No manual step ‚Üí fully event-driven.

Lambda Function Executes

Lambda takes the uploaded image.

Generates a smaller thumbnail version.

Push to S3

The new thumbnail is stored back into S3 (often in a different bucket/folder).

Now you have both the full-size image + the thumbnail.

Store Metadata in DynamoDB

Lambda also records details about the image (name, size, timestamp, etc.).

Stored in DynamoDB for easy querying later.

üîπ Why This Is Cool

Fully Automated ‚Üí just upload the image, everything else happens automatically.

Serverless ‚Üí no servers to manage, AWS handles scaling.

Cost-Efficient ‚Üí pay only when Lambda runs + storage costs.

Scalable ‚Üí works whether 1 image or 1 million images are uploaded.

<img width="510" height="284" alt="image" src="https://github.com/user-attachments/assets/d7c0fb02-609e-4b75-87cf-e59f7034d32c" />

Example: Scheduled Task with EventBridge + Lambda
üîπ Flow

EventBridge (CloudWatch Events)

Acts like a scheduler/cron job.

Example: trigger every 1 hour.

Can be set to run at specific times/dates using cron expressions.

Lambda Function

Triggered automatically by EventBridge.

Runs your code only when scheduled.

Can perform tasks like:

Backups

Cleanup jobs

Generating reports

Interacting with other AWS services (e.g., S3, DynamoDB, EC2).

üîπ Why This Is Useful

Event-driven ‚Üí runs only when triggered.

No servers ‚Üí no need for a VM running 24/7.

Cost-effective ‚Üí you only pay when Lambda runs.

Flexible scheduling ‚Üí run every minute, hour, day, or custom cron timing.

‚úÖ Summary:
EventBridge = scheduler
Lambda = worker
Together ‚Üí fully managed, cost-efficient way to automate recurring tasks in AWS.


<img width="407" height="255" alt="image" src="https://github.com/user-attachments/assets/47c98910-dc61-43ab-98e7-e7fab861abe4" />


##Amazon Netwirking 
Understanding CIDR - IPv4
classless inter domain routing 
CIDR is a method for allocating IP[ addresses 
CIDR help us define IP ranges 
if an IP address  has XX.XX.XX.XX/(ANYMUMBER) - 1 IP
if an ip is 0.0.0.0/0 is is public 

CIDR consists of two components 
BASE IP
represents an Ip congaienr range 
ecxample 10.0.0.0,192168.0.0
Subnet mask
Defioes how many bits and IP can chnage 
exampple /0/24/32
can take 2 forms 
/8  √≥  255.0.0.0
/16 √≥  255.255.0.0
/24 √≥  255.255.255.0
/32 √≥  255.255.255.255

visual break down 
Here‚Äôs a visual breakdown of CIDR:

Blue = network bits (fixed, define the subnet)

Gray = host bits (variable, used for devices inside the subnet)

/8 ‚Üí Huge network, many hosts (16M+)

/16 ‚Üí Medium network (65K hosts)

/24 ‚Üí Small network (254 hosts, common in LANs)

/32 ‚Üí Single device (no host bits left)

This way, you can literally see how the prefix length (/X) shrinks the host space and increases network specificity.
<img width="1979" height="1180" alt="output" src="https://github.com/user-attachments/assets/bbbeccd5-da9d-4a88-9e51-54a213992221" />

Understanding CIDR - subnet mask 
A subnet mask (or CIDR slash notation) defines how many IP addresses exist in a subnet.

/32 ‚Üí Only 1 IP (usually assigned to a single host).

/31 ‚Üí 2 IPs

/30 ‚Üí 4 IPs

/29 ‚Üí 8 IPs

/28 ‚Üí 16 IPs

/27 ‚Üí 32 IPs

/26 ‚Üí 64 IPs

/25 ‚Üí 128 IPs

/24 ‚Üí 256 IPs

/16 ‚Üí 65,536 IPs

/0 ‚Üí Covers all IPs (entire IPv4 space)

üëâ Notice how each step doubles the number of available IPs. That‚Äôs because each time you reduce the subnet mask (make it less restrictive), you free up one more host bit, which doubles the possible addresses.

üîπ Octet Relationship (from the image)

Think of an IP address as 4 octets (192.168.0.0 for example).

/32 ‚Üí No octet can change ‚Üí one IP

/24 ‚Üí Last octet can change (0‚Äì255) ‚Üí 256 IPs

/16 ‚Üí Last two octets can change (0‚Äì255.0‚Äì255) ‚Üí 65,536 IPs

/8 ‚Üí Last three octets can change ‚Üí 16.7 million IPs

/0 ‚Üí All octets can change ‚Üí every IPv4 address

üîπ Example Walkthrough

Let‚Äôs take 192.168.0.0/30:

Subnet mask: 255.255.255.252

Binary: 11111111.11111111.11111111.11111100

Host bits: 2 (the last two zeroes)

Total IPs = 2¬≤ = 4

That gives you:

192.168.0.0 ‚Üí Network address  
192.168.0.1 ‚Üí Usable host  
192.168.0.2 ‚Üí Usable host  
192.168.0.3 ‚Üí Broadcast address


So /30 means 2 usable IPs for devices.

üîπ Why This Matters (AWS & VPC Example)

In AWS, when you create a VPC (Virtual Private Cloud) or subnets, you must plan how many IPs you‚Äôll need:

/16 ‚Üí Large network, ~65K IPs (used for VPC range).

/24 ‚Üí Smaller subnet, 256 IPs (commonly used for private or public subnets).

This way, you don‚Äôt run out of addresses, and you don‚Äôt waste too many.

‚úÖ Summary:

Subnet masks tell you how many IPs are in a range.

The number of IPs doubles each time you increase host bits by 1.

CIDR /X ‚Üí smaller number means more hosts, larger number means more specific, fewer hosts.

AWS typically uses /16 (for VPCs) and /24 (for subnets).
<img width="780" height="264" alt="image" src="https://github.com/user-attachments/assets/bc6023a1-715e-4af6-b137-74334891b7a4" />

public vs private IPV4 
1. Private IPv4 Addresses

The IANA (Internet Assigned Numbers Authority) reserved specific IP ranges for private use only. These addresses are not routable on the public internet ‚Äî they are meant for local networks (like your home Wi-Fi, office LAN, or cloud VPC).

The reserved private ranges are:

10.0.0.0 ‚Üí 10.255.255.255 (10/8 range)

172.16.0.0 ‚Üí 172.31.255.255 (172.16/12 range)

192.168.0.0 ‚Üí 192.168.255.255 (192.168/16 range)

üëâ Example:

Your home router might give your laptop an IP like 192.168.1.10.

That IP works inside your house, but no one on the internet can reach it directly.

Special note:

127.0.0.1 = Loopback address ‚Üí used to test networking on your own computer (‚Äúlocalhost‚Äù).

üîπ 2. Public IPv4 Addresses

Any IPv4 address outside those private ranges is a public IP.

These can be accessed from anywhere on the internet (as long as firewalls or ISPs don‚Äôt block them).

Websites, servers, and cloud services usually use public IPs so users around the world can connect.

üëâ Example:

Google DNS: 8.8.8.8 ‚Üí Public

A website‚Äôs server might be 203.0.113.25 ‚Üí Public

üîπ 3. How They Work Together

Your home devices use private IPs (e.g., 192.168.1.20).

Your router has a public IP assigned by your ISP (e.g., 81.2.69.142).

NAT (Network Address Translation) maps your private IPs ‚Üí public IP, so you can browse the internet.

Without NAT and private IP ranges, we would‚Äôve run out of IPv4 addresses decades ago.

‚úÖ Summary:

Private IPs = Local networks only (10.x.x.x, 172.16‚Äì31.x.x, 192.168.x.x).

Public IPs = Routable on the internet, used by websites & servers.

Loopback (127.0.0.1) = Your own machine, for local testing.

NAT lets private IP devices share one public IP to connect online.

default vpc 
Default VPC (what you get automatically)

Comes with your AWS account (1 per region).

Already has internet access via an Internet Gateway.

Has 1 public subnet per AZ.

EC2s launched here get a public + private IPv4 by default.

EC2s also get DNS names (public + private).

Includes a default security group + route table.

VPC in AWS
AWS VPC (Virtual Private Cloud) Notes

A VPC = your own private network in AWS (like a mini data center).

You can have up to 5 VPCs per region by default (limit can be increased).

üîπ CIDR Range Limits

Smallest: /28 ‚Üí 16 IPs

Largest: /16 ‚Üí 65,536 IPs

üîπ Allowed Private IP Ranges

10.0.0.0/8 ‚Üí very large networks

172.16.0.0 ‚Äì 172.31.255.255 (/12) ‚Üí AWS commonly uses 172.31.0.0/16 for default VPCs

192.168.0.0/16 ‚Üí common for home networks

üîπ Important Rule

üö® VPC CIDR must not overlap with:

Other VPCs

Your corporate network

Any connected network

Otherwise, routing will break.

üëâ In short:
A VPC gives you a custom private network in AWS, with flexible IP ranges, but you need to plan the CIDR carefully to avoid overlap.

VPC - subnet IPv4 
Subnets in a VPC

Subnets = smaller networks inside your VPC.

Spread across Availability Zones (AZs) for redundancy & high availability.

Can be:

Public subnet ‚Üí internet access allowed.

Private subnet ‚Üí no direct internet access.

üîπ AWS Reserves 5 IPs in Every Subnet

Example: 10.0.0.0/24 ‚Üí 256 IPs total, but 5 are reserved:

.0 ‚Üí Network address

.1 ‚Üí VPC router

.2 ‚Üí Amazon DNS

.3 ‚Üí Future use

.255 ‚Üí Broadcast (AWS doesn‚Äôt use broadcast, but still reserved)

üëâ So usable IPs = total - 5.

üîπ Example of Planning

/27 = 32 IPs ‚Üí usable = 27 (too small for 29 instances).

/26 = 64 IPs ‚Üí usable = 59 (fits 29 instances).

Internet gateway 
alloews resources in a vpc to connect ot the internet 
scales horizontally and is highlly avalible and redundant must be created seperatkly from a VPC
one VPC van onoy be attached to one IGW and ect
IGW on their own do not allow iunternet access
rouite tables must also be updated 

bastion hosts 
hat is a Bastion Host?

A bastion host = a special EC2 instance in a public subnet.

Acts as a secure bridge to reach private EC2 instances in a private subnet.

You SSH into the bastion first, then from there into your private instances.

üîπ Why Do We Need Them?

Private EC2 instances (databases, backends) should not be exposed to the internet.

But admins still need a way to log in for maintenance/updates.

Bastion hosts provide a controlled, secure entry point.

üîπ How It Works (with your diagram)

Bastion Host sits in a public subnet.

You SSH into the bastion from your office/home IP.

From the bastion, you SSH into private EC2s inside the private subnet.

üîπ Security Best Practices

Bastion Security Group ‚Üí only allow inbound SSH from trusted IPs (e.g., office IP range).

Private EC2 Security Group ‚Üí only allow inbound SSH from the bastion host (not the whole internet).

Use key pairs or even MFA for stronger access control.

‚úÖ Summary:
A bastion host = secure gateway to private EC2s. It prevents exposing sensitive systems directly to the internet while still allowing admins safe access when needed.

Walkthrough of the Diagram

User (Admin)

You (the admin) are outside the VPC.

You connect via SSH into the bastion host.

Public Subnet (Top Box)

Contains the bastion host EC2 instance.

Security Group (BastionHost-SG) only allows SSH from trusted IPs (like your office or home).

Private Subnet (Bottom Box)

Contains the private EC2 instances (databases, backend servers).

These cannot be reached from the internet directly.

Security Group (LinuxInstance-SG) allows SSH only from the bastion host.

Flow

You ‚Üí SSH into Bastion Host (public subnet).

Bastion Host ‚Üí SSH into Private EC2s (private subnet).

üîπ Key Point

The bastion host acts as the middleman:

Publicly accessible but restricted (secure).

Lets you safely reach private instances without exposing them to the internet.
<img width="277" height="380" alt="image" src="https://github.com/user-attachments/assets/3ae70930-5bfc-4952-960f-8e4313d784d2" />

NAT gateway 
What is a NAT Gateway?

NAT = Network Address Translation

Lets private subnet instances access the internet (updates, APIs, patches).

Blocks inbound traffic ‚Üí internet cannot reach private instances.

üîπ Why It‚Äôs Important

Keeps private resources secure (not exposed).

Still allows outbound internet access when needed.

üîπ Key Features

Fully managed by AWS ‚Üí no patching, scaling, or maintenance.

High bandwidth ‚Üí 5 Gbps baseline, auto-scales up to 100 Gbps.

AZ specific ‚Üí must deploy 1 per Availability Zone for redundancy.

Uses an Elastic IP for outbound connections.

Requires an Internet Gateway (NAT gateway ‚Üí Internet Gateway ‚Üí Internet).

No Security Groups needed (unlike NAT instances).

üîπ Limitations

Instances in the same subnet as the NAT gateway can‚Äôt use it.

Billed hourly + per GB of traffic ‚Üí can get costly at scale.

üîπ Typical Setup

Private Subnet ‚Üí routes outbound traffic ‚Üí NAT Gateway (in Public Subnet) ‚Üí Internet Gateway ‚Üí Internet.

‚úÖ Summary:
A NAT Gateway = a secure, managed bridge for private subnet instances to reach the internet outbound only, while keeping them safe from inbound internet traffic

NAT Gateway with High Availability
NAT Gateway & High Availability
1. The Setup (from the diagram)

VPC has:

Public Subnets (top row) ‚Üí each with a NAT Gateway.

Private Subnets (bottom row) ‚Üí EC2 instances.

NAT Gateways connect ‚Üí Internet Gateway ‚Üí Internet.

Router handles the routing between subnets.

2. The Problem (Single NAT Gateway)

NAT Gateways are AZ-specific.

If you only have one NAT Gateway in AZ-A, and AZ-A goes down:

‚úÖ EC2s in AZ-B are still running.

‚ùå But they lose internet access, because their traffic depended on the NAT Gateway in AZ-A.

3. The Solution (Multiple NAT Gateways)

Deploy a NAT Gateway in each AZ where you have resources.

Example:

NAT Gateway in AZ-A ‚Üí serves EC2s in AZ-A.

NAT Gateway in AZ-B ‚Üí serves EC2s in AZ-B.

If one AZ fails, the other AZ still has internet connectivity.

üîπ Why This Matters

High Availability ‚Üí avoids single points of failure.

Disaster Recovery ‚Üí ensures your private workloads (databases, app servers) can still reach the internet for updates/APIs.

‚úÖ Summary:
A NAT Gateway is only highly available within its own AZ. To achieve true high availability across multiple AZs, deploy one NAT Gateway per AZ.
<img width="417" height="439" alt="image" src="https://github.com/user-attachments/assets/74f9fd5f-9753-497f-8ac4-c7a0d2fa3cb1" />

NAT Gateway vs NAT Instance
| Feature              | **NAT Gateway** üü¶                                | **NAT Instance** üüß                          |
| -------------------- | ------------------------------------------------- | -------------------------------------------- |
| **Availability**     | HA within an AZ (deploy 1 per AZ for multi-AZ HA) | No built-in HA (needs failover scripts)      |
| **Bandwidth**        | Up to **100 Gbps**, auto-scales                   | Limited by EC2 instance type                 |
| **Maintenance**      | Fully managed by AWS (no patches/updates)         | You manage OS, patches, scaling              |
| **Cost Model**       | Simple: hourly + per GB data transfer             | Based on EC2 instance type + network charges |
| **Elastic IP**       | Requires Elastic IP                               | Requires Elastic IP                          |
| **Security Groups**  | Not needed (AWS manages security)                 | Can attach SGs like any EC2                  |
| **Bastion Host Use** | ‚ùå No (only forwards traffic)                      | ‚úÖ Yes (can double as bastion host/jump box)  |
| **Scaling**          | Auto-scales                                       | Manual (resize EC2 or add more)              |
Summary

NAT Gateway ‚Üí Best for production: scalable, simple, low maintenance, but higher cost.

NAT Instance ‚Üí More flexible & cheaper for small setups, but requires manual management and gives you extra options (like doubling as a bastion host).
<img width="764" height="338" alt="image" src="https://github.com/user-attachments/assets/da1c6e6d-6adb-4aee-afa8-8c9a9e51d19e" />
üîπ NACLs (Network Access Control Lists)
1. Basics

Work at the subnet level (1 NACL per subnet).

Act like a big filter that allows or denies traffic.

Every subnet gets a default NACL, but you can create custom ones.

2. Key Characteristics

Stateless ‚Üí return traffic isn‚Äôt automatically allowed (must add both inbound + outbound rules).

Rules are numbered (1‚Äì32766) ‚Üí

Lower numbers = higher precedence.

First match wins (no further rules are checked).

Catchall rule (*) at the end ‚Üí denies everything not explicitly allowed.

3. Example

Rule #100: ALLOW 10.0.0.10/32

Rule #200: DENY 10.0.0.10/32
üëâ Rule #100 takes precedence (lower number wins).

4. Best Practices

Use rule numbers in increments of 100 (100, 200, 300, ‚Ä¶) ‚Üí easy to insert new rules later.

Use NACLs for broad subnet-level blocking (e.g., block malicious IPs).

5. Why Use NACLs?

Extra layer of security on top of Security Groups.

Good for subnet-wide rules (affects all resources in that subnet).

Useful for blocking specific IPs/ranges before they reach your instances.

‚úÖ In summary:
NACLs = stateless subnet firewalls. They control traffic in/out of a subnet with numbered rules (first match wins). Great for broad blocking and defense in depth.






















































































































